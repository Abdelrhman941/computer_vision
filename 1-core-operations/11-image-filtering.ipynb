{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Verify libraries\n",
    "print(f\"‚úÖ OpenCV Version: {cv2.__version__}\")\n",
    "print(f\"‚úÖ NumPy Version: {np.__version__}\")\n",
    "print(f\"‚úÖ Matplotlib Version: {plt.matplotlib.__version__}\")\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs('../assets/outputs/01_image_filtering', exist_ok=True)\n",
    "print(\"‚úÖ Image filtering setup completed!\")\n",
    "\n",
    "# Configure matplotlib for better display\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "plt.rcParams['axes.titlesize'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare sample image\n",
    "print(\"üñºÔ∏è Loading sample image for filtering demonstrations...\")\n",
    "\n",
    "# Try to load an image from the assets folder\n",
    "image_path = '../assets/input-images/image1.png'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "if image is None:\n",
    "    # Create a synthetic test image if no image is available\n",
    "    print(\"üì∑ Creating synthetic test image for demonstration...\")\n",
    "    image = np.zeros((400, 600, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Add some geometric shapes for filtering demonstration\n",
    "    cv2.rectangle(image, (50, 50), (200, 150), (255, 255, 255), -1)\n",
    "    cv2.circle(image, (400, 100), 80, (128, 128, 128), -1)\n",
    "    cv2.rectangle(image, (300, 200), (550, 350), (200, 200, 200), -1)\n",
    "    \n",
    "    # Add some noise for filtering demonstration\n",
    "    noise = np.random.randint(0, 50, image.shape, dtype=np.uint8)\n",
    "    image = cv2.add(image, noise)\n",
    "    \n",
    "    print(\"‚úÖ Synthetic test image created\")\n",
    "else:\n",
    "    print(f\"‚úÖ Image loaded: {image.shape}\")\n",
    "\n",
    "# Convert to RGB for matplotlib display\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Define various kernels for demonstration\n",
    "kernels = {\n",
    "    'Identity': np.array([[0, 0, 0],\n",
    "                         [0, 1, 0],\n",
    "                         [0, 0, 0]]),\n",
    "    \n",
    "    'Sharpening': np.array([[0, -1, 0],\n",
    "                           [-1, 5, -1],\n",
    "                           [0, -1, 0]]),\n",
    "    \n",
    "    'Edge Detection': np.array([[-1, -1, -1],\n",
    "                               [-1, 8, -1],\n",
    "                               [-1, -1, -1]]),\n",
    "    \n",
    "    'Emboss': np.array([[-2, -1, 0],\n",
    "                       [-1, 1, 1],\n",
    "                       [0, 1, 2]]),\n",
    "    \n",
    "    'Gaussian Blur': np.array([[1, 2, 1],\n",
    "                              [2, 4, 2],\n",
    "                              [1, 2, 1]]) / 16,\n",
    "    \n",
    "    'Box Blur': np.ones((5, 5)) / 25\n",
    "}\n",
    "\n",
    "print(f\"üìä Created {len(kernels)} different kernels for demonstration\")\n",
    "\n",
    "# Apply all kernels and create comparison\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Show original image\n",
    "axes[0].imshow(image_rgb)\n",
    "axes[0].set_title('Original Image', fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Apply each kernel\n",
    "for idx, (name, kernel) in enumerate(kernels.items(), 1):\n",
    "    filtered = cv2.filter2D(image, -1, kernel)\n",
    "    filtered_rgb = cv2.cvtColor(filtered, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    axes[idx].imshow(filtered_rgb)\n",
    "    axes[idx].set_title(f'{name} Filter', fontweight='bold')\n",
    "    axes[idx].axis('off')\n",
    "    \n",
    "    # Save individual filtered images\n",
    "    cv2.imwrite(f'../assets/outputs/01_image_filtering/filter_{name.lower().replace(\" \", \"_\")}.png', filtered)\n",
    "\n",
    "# Hide the last subplot if not used\n",
    "if len(kernels) + 1 < len(axes):\n",
    "    axes[-1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../assets/outputs/01_image_filtering/convolution_filters_comparison.png', \n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"üíæ Convolution filter results saved\")\n",
    "print(\"‚úÖ Custom kernel filtering demonstration completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive blur techniques demonstration\n",
    "print(\"üå´Ô∏è Demonstrating various blur techniques...\")\n",
    "\n",
    "# Create a noisy test image for better demonstration\n",
    "test_image = image.copy()\n",
    "\n",
    "# Add different types of noise\n",
    "salt_pepper_noise = np.random.random(test_image.shape[:2])\n",
    "test_image[salt_pepper_noise < 0.02] = 0  # Salt noise (black pixels)\n",
    "test_image[salt_pepper_noise > 0.98] = 255  # Pepper noise (white pixels)\n",
    "\n",
    "# Add Gaussian noise\n",
    "gaussian_noise = np.random.normal(0, 25, test_image.shape).astype(np.uint8)\n",
    "test_image = cv2.add(test_image, gaussian_noise)\n",
    "\n",
    "print(\"‚úÖ Added salt-and-pepper + Gaussian noise for demonstration\")\n",
    "\n",
    "# Apply different blur techniques\n",
    "blur_results = {}\n",
    "\n",
    "# 1. Mean Blur (Box Filter)\n",
    "blur_results['Mean Blur (5x5)'] = cv2.blur(test_image, (5, 5))\n",
    "blur_results['Mean Blur (15x15)'] = cv2.blur(test_image, (15, 15))\n",
    "\n",
    "# 2. Median Blur\n",
    "blur_results['Median Blur (5)'] = cv2.medianBlur(test_image, 5)\n",
    "blur_results['Median Blur (15)'] = cv2.medianBlur(test_image, 15)\n",
    "\n",
    "# 3. Gaussian Blur\n",
    "blur_results['Gaussian Blur (5x5)'] = cv2.GaussianBlur(test_image, (5, 5), 0)\n",
    "blur_results['Gaussian Blur (15x15)'] = cv2.GaussianBlur(test_image, (15, 15), 0)\n",
    "\n",
    "# 4. Bilateral Filter\n",
    "blur_results['Bilateral Filter'] = cv2.bilateralFilter(test_image, 9, 75, 75)\n",
    "\n",
    "print(f\"üìä Applied {len(blur_results)} different blur techniques\")\n",
    "\n",
    "# Create comprehensive comparison\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Show original and noisy images\n",
    "axes[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original Image', fontweight='bold', fontsize=12)\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title('Noisy Image\\n(Salt & Pepper + Gaussian)', fontweight='bold', fontsize=12)\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Show blur results\n",
    "for idx, (name, blurred) in enumerate(blur_results.items(), 2):\n",
    "    if idx < len(axes):\n",
    "        axes[idx].imshow(cv2.cvtColor(blurred, cv2.COLOR_BGR2RGB))\n",
    "        axes[idx].set_title(name, fontweight='bold', fontsize=11)\n",
    "        axes[idx].axis('off')\n",
    "        \n",
    "        # Save individual results\n",
    "        filename = name.lower().replace(' ', '_').replace('(', '').replace(')', '').replace('x', '')\n",
    "        cv2.imwrite(f'../assets/outputs/01_image_filtering/blur_{filename}.png', blurred)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../assets/outputs/01_image_filtering/blur_techniques_comparison.png', \n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Demonstrate the effectiveness of different blur types\n",
    "print(\"\\nüìà Blur Technique Analysis:\")\n",
    "print(\"üîπ Mean Blur: Simple averaging, can blur edges\")\n",
    "print(\"üîπ Median Blur: Excellent for salt-and-pepper noise, preserves edges\")\n",
    "print(\"üîπ Gaussian Blur: Natural-looking blur, good for preprocessing\")\n",
    "print(\"üîπ Bilateral Filter: Best noise reduction while preserving edges\")\n",
    "\n",
    "print(\"üíæ Blur comparison results saved\")\n",
    "print(\"‚úÖ Blur techniques demonstration completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Edge Detection Filters**\n",
    "\n",
    "### **Edge Detection Techniques:**\n",
    "\n",
    "| Function | Purpose | Characteristics | Best For |\n",
    "|----------|---------|----------------|----------|\n",
    "| `cv2.Sobel()` | **Gradient-based** | Directional (X, Y) | Directional edges |\n",
    "| `cv2.Laplacian()` | **Second derivative** | All directions | General edge detection |\n",
    "| `cv2.Canny()` | **Multi-stage** | Optimal edge detection | High-quality edges |\n",
    "| `cv2.Scharr()` | **Improved Sobel** | Better accuracy | Precise edge detection |\n",
    "\n",
    "### **Edge Detection Process:**\n",
    "1. **Preprocessing**: Apply Gaussian blur to reduce noise\n",
    "2. **Gradient Calculation**: Find intensity changes\n",
    "3. **Thresholding**: Separate edges from non-edges\n",
    "4. **Post-processing**: Thin edges and remove weak edges\n",
    "\n",
    "### **Applications:**\n",
    "- **Object Detection**: Finding object boundaries\n",
    "- **Feature Extraction**: Identifying important structures\n",
    "- **Image Segmentation**: Separating regions\n",
    "- **Quality Control**: Detecting defects and anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive edge detection demonstration\n",
    "print(\"üîç Demonstrating edge detection techniques...\")\n",
    "\n",
    "# Convert to grayscale for edge detection (edges work better on grayscale)\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Gaussian blur to reduce noise before edge detection\n",
    "blurred_gray = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "\n",
    "# Edge detection techniques\n",
    "edge_results = {}\n",
    "\n",
    "# 1. Sobel Edge Detection (X and Y gradients)\n",
    "sobel_x = cv2.Sobel(blurred_gray, cv2.CV_64F, 1, 0, ksize=3)  # X gradient\n",
    "sobel_y = cv2.Sobel(blurred_gray, cv2.CV_64F, 0, 1, ksize=3)  # Y gradient\n",
    "sobel_combined = np.sqrt(sobel_x**2 + sobel_y**2)  # Magnitude\n",
    "sobel_combined = np.uint8(np.clip(sobel_combined, 0, 255))\n",
    "\n",
    "edge_results['Sobel X'] = np.uint8(np.clip(np.abs(sobel_x), 0, 255))\n",
    "edge_results['Sobel Y'] = np.uint8(np.clip(np.abs(sobel_y), 0, 255))\n",
    "edge_results['Sobel Combined'] = sobel_combined\n",
    "\n",
    "# 2. Laplacian Edge Detection\n",
    "laplacian = cv2.Laplacian(blurred_gray, cv2.CV_64F)\n",
    "edge_results['Laplacian'] = np.uint8(np.clip(np.abs(laplacian), 0, 255))\n",
    "\n",
    "# 3. Scharr Edge Detection (improved Sobel)\n",
    "scharr_x = cv2.Scharr(blurred_gray, cv2.CV_64F, 1, 0)\n",
    "scharr_y = cv2.Scharr(blurred_gray, cv2.CV_64F, 0, 1)\n",
    "scharr_combined = np.sqrt(scharr_x**2 + scharr_y**2)\n",
    "edge_results['Scharr Combined'] = np.uint8(np.clip(scharr_combined, 0, 255))\n",
    "\n",
    "# 4. Canny Edge Detection (the gold standard)\n",
    "edge_results['Canny (50, 150)'] = cv2.Canny(blurred_gray, 50, 150)\n",
    "edge_results['Canny (100, 200)'] = cv2.Canny(blurred_gray, 100, 200)\n",
    "\n",
    "print(f\"üìä Applied {len(edge_results)} edge detection techniques\")\n",
    "\n",
    "# Create comprehensive edge detection comparison\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Show original and grayscale images\n",
    "axes[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original Image', fontweight='bold', fontsize=12)\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(gray_image, cmap='gray')\n",
    "axes[1].set_title('Grayscale Image', fontweight='bold', fontsize=12)\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Show edge detection results\n",
    "for idx, (name, edges) in enumerate(edge_results.items(), 2):\n",
    "    if idx < len(axes):\n",
    "        axes[idx].imshow(edges, cmap='gray')\n",
    "        axes[idx].set_title(name, fontweight='bold', fontsize=11)\n",
    "        axes[idx].axis('off')\n",
    "        \n",
    "        # Save individual results\n",
    "        filename = name.lower().replace(' ', '_').replace('(', '').replace(')', '').replace(',', '')\n",
    "        cv2.imwrite(f'../assets/outputs/01_image_filtering/edge_{filename}.png', edges)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../assets/outputs/01_image_filtering/edge_detection_comparison.png', \n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Create detailed Canny edge detection analysis\n",
    "print(\"\\nüéØ Detailed Canny Edge Detection Analysis...\")\n",
    "\n",
    "# Test different Canny thresholds\n",
    "canny_thresholds = [(30, 100), (50, 150), (100, 200), (150, 250)]\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, (low, high) in enumerate(canny_thresholds):\n",
    "    canny_result = cv2.Canny(blurred_gray, low, high)\n",
    "    axes[idx].imshow(canny_result, cmap='gray')\n",
    "    axes[idx].set_title(f'Canny Edges\\nLow: {low}, High: {high}', fontweight='bold')\n",
    "    axes[idx].axis('off')\n",
    "    \n",
    "    cv2.imwrite(f'../assets/outputs/01_image_filtering/canny_{low}_{high}.png', canny_result)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../assets/outputs/01_image_filtering/canny_threshold_analysis.png', \n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìà Edge Detection Analysis:\")\n",
    "print(\"üîπ Sobel: Good for directional edge detection\")\n",
    "print(\"üîπ Laplacian: Detects edges in all directions simultaneously\")\n",
    "print(\"üîπ Scharr: More accurate than Sobel for small kernels\")\n",
    "print(\"üîπ Canny: Best overall edge detector with hysteresis thresholding\")\n",
    "\n",
    "print(\"üíæ Edge detection results saved\")\n",
    "print(\"‚úÖ Edge detection demonstration completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Morphological Operations**\n",
    "\n",
    "### **Non-linear Filtering Techniques:**\n",
    "\n",
    "| Operation | Purpose | Effect | Best For |\n",
    "|-----------|---------|--------|----------|\n",
    "| `cv2.erode()` | **Erosion** | Shrinks white regions | Removing noise, separating objects |\n",
    "| `cv2.dilate()` | **Dilation** | Expands white regions | Filling gaps, joining broken parts |\n",
    "| `cv2.morphologyEx()` | **Opening** | Erosion + Dilation | Removing small noise |\n",
    "| `cv2.morphologyEx()` | **Closing** | Dilation + Erosion | Filling small holes |\n",
    "| `cv2.morphologyEx()` | **Gradient** | Dilation - Erosion | Edge detection |\n",
    "| `cv2.morphologyEx()` | **Top Hat** | Original - Opening | Bright objects on dark background |\n",
    "| `cv2.morphologyEx()` | **Black Hat** | Closing - Original | Dark objects on bright background |\n",
    "\n",
    "### **Structuring Elements:**\n",
    "- **Rectangular**: `cv2.getStructuringElement(cv2.MORPH_RECT, (w,h))`\n",
    "- **Elliptical**: `cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (w,h))`\n",
    "- **Cross**: `cv2.getStructuringElement(cv2.MORPH_CROSS, (w,h))`\n",
    "\n",
    "### **Applications:**\n",
    "- **Text Processing**: Cleaning up scanned documents\n",
    "- **Medical Imaging**: Analyzing cell structures\n",
    "- **Object Analysis**: Shape analysis and feature extraction\n",
    "- **Noise Removal**: Cleaning binary images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Morphological operations demonstration\n",
    "print(\"üîß Demonstrating morphological operations...\")\n",
    "\n",
    "# Create a binary test image for morphological operations\n",
    "# Convert to grayscale and threshold to create binary image\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "_, binary_image = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Add some noise to demonstrate cleaning effects\n",
    "noisy_binary = binary_image.copy()\n",
    "# Add salt and pepper noise\n",
    "noise = np.random.random(noisy_binary.shape)\n",
    "noisy_binary[noise < 0.05] = 0  # Pepper noise\n",
    "noisy_binary[noise > 0.95] = 255  # Salt noise\n",
    "\n",
    "print(\"‚úÖ Created binary test image with noise\")\n",
    "\n",
    "# Define different structuring elements\n",
    "kernels = {\n",
    "    'Rectangular (5x5)': cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5)),\n",
    "    'Elliptical (5x5)': cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5)),\n",
    "    'Cross (5x5)': cv2.getStructuringElement(cv2.MORPH_CROSS, (5, 5))\n",
    "}\n",
    "\n",
    "# Use rectangular kernel for main demonstrations\n",
    "kernel = kernels['Rectangular (5x5)']\n",
    "\n",
    "# Apply morphological operations\n",
    "morph_results = {}\n",
    "\n",
    "# Basic operations\n",
    "morph_results['Original Binary'] = binary_image\n",
    "morph_results['Noisy Binary'] = noisy_binary\n",
    "morph_results['Erosion'] = cv2.erode(noisy_binary, kernel, iterations=1)\n",
    "morph_results['Dilation'] = cv2.dilate(noisy_binary, kernel, iterations=1)\n",
    "\n",
    "# Complex operations using morphologyEx\n",
    "morph_results['Opening'] = cv2.morphologyEx(noisy_binary, cv2.MORPH_OPEN, kernel)\n",
    "morph_results['Closing'] = cv2.morphologyEx(noisy_binary, cv2.MORPH_CLOSE, kernel)\n",
    "morph_results['Gradient'] = cv2.morphologyEx(noisy_binary, cv2.MORPH_GRADIENT, kernel)\n",
    "morph_results['Top Hat'] = cv2.morphologyEx(noisy_binary, cv2.MORPH_TOPHAT, kernel)\n",
    "morph_results['Black Hat'] = cv2.morphologyEx(noisy_binary, cv2.MORPH_BLACKHAT, kernel)\n",
    "\n",
    "print(f\"üìä Applied {len(morph_results)} morphological operations\")\n",
    "\n",
    "# Create comprehensive morphological operations comparison\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, (name, result) in enumerate(morph_results.items()):\n",
    "    if idx < len(axes):\n",
    "        axes[idx].imshow(result, cmap='gray')\n",
    "        axes[idx].set_title(name, fontweight='bold', fontsize=11)\n",
    "        axes[idx].axis('off')\n",
    "        \n",
    "        # Save individual results\n",
    "        filename = name.lower().replace(' ', '_').replace('(', '').replace(')', '')\n",
    "        cv2.imwrite(f'../assets/outputs/01_image_filtering/morph_{filename}.png', result)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../assets/outputs/01_image_filtering/morphological_operations.png', \n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Demonstrate different kernel shapes\n",
    "print(\"\\nüîç Comparing different structuring elements...\")\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Show the kernels themselves\n",
    "for idx, (name, kern) in enumerate(kernels.items()):\n",
    "    axes[0, idx].imshow(kern, cmap='gray', interpolation='nearest')\n",
    "    axes[0, idx].set_title(f'{name}\\nStructuring Element', fontweight='bold')\n",
    "    axes[0, idx].axis('off')\n",
    "    \n",
    "    # Apply opening operation with each kernel\n",
    "    opening_result = cv2.morphologyEx(noisy_binary, cv2.MORPH_OPEN, kern)\n",
    "    axes[1, idx].imshow(opening_result, cmap='gray')\n",
    "    axes[1, idx].set_title(f'Opening with\\n{name}', fontweight='bold')\n",
    "    axes[1, idx].axis('off')\n",
    "    \n",
    "    # Save kernel comparison results\n",
    "    filename = name.lower().replace(' ', '_').replace('(', '').replace(')', '')\n",
    "    cv2.imwrite(f'../assets/outputs/01_image_filtering/kernel_{filename}.png', opening_result)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../assets/outputs/01_image_filtering/kernel_comparison.png', \n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìà Morphological Operations Analysis:\")\n",
    "print(\"üîπ Erosion: Removes small white noise, shrinks objects\")\n",
    "print(\"üîπ Dilation: Fills small black holes, expands objects\")\n",
    "print(\"üîπ Opening: Removes small noise while preserving shape\")\n",
    "print(\"üîπ Closing: Fills small holes while preserving shape\")\n",
    "print(\"üîπ Gradient: Finds object boundaries\")\n",
    "print(\"üîπ Top Hat: Finds bright spots on dark background\")\n",
    "print(\"üîπ Black Hat: Finds dark spots on bright background\")\n",
    "\n",
    "print(\"üíæ Morphological operations results saved\")\n",
    "print(\"‚úÖ Morphological operations demonstration completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Practical Applications & Best Practices**\n",
    "\n",
    "### **Real-world Applications:**\n",
    "\n",
    "| Application | Techniques Used | Purpose |\n",
    "|-------------|----------------|---------|\n",
    "| **Medical Imaging** | Gaussian blur + Canny edges | Tumor detection, organ segmentation |\n",
    "| **Quality Control** | Morphological ops + edge detection | Defect detection in manufacturing |\n",
    "| **Document Processing** | Morphological ops + thresholding | Text cleaning, OCR preprocessing |\n",
    "| **Autonomous Vehicles** | Gaussian blur + Sobel/Canny | Lane detection, obstacle recognition |\n",
    "| **Satellite Imagery** | Various filters + enhancement | Geographic feature extraction |\n",
    "| **Biometrics** | Edge detection + morphological | Fingerprint/iris pattern analysis |\n",
    "\n",
    "### **Best Practices:**\n",
    "\n",
    "#### **Filter Selection Guidelines:**\n",
    "- üîπ **Noise Reduction**: Start with Gaussian blur or median filter\n",
    "- üîπ **Edge Detection**: Use Canny for best results, Sobel for directional\n",
    "- üîπ **Shape Analysis**: Apply morphological operations on binary images\n",
    "- üîπ **Preprocessing**: Always consider your end goal when choosing filters\n",
    "\n",
    "#### **Parameter Tuning:**\n",
    "- üîπ **Kernel Size**: Larger kernels = more smoothing/stronger effect\n",
    "- üîπ **Threshold Values**: Adjust based on image contrast and noise level\n",
    "- üîπ **Iterations**: More iterations = stronger morphological effects\n",
    "- üîπ **Sigma Values**: Higher sigma = more Gaussian smoothing\n",
    "\n",
    "#### **Common Pitfalls:**\n",
    "- ‚ùå **Over-filtering**: Removes important details\n",
    "- ‚ùå **Under-filtering**: Leaves too much noise\n",
    "- ‚ùå **Wrong order**: Apply operations in logical sequence\n",
    "- ‚ùå **Ignoring image type**: Binary vs grayscale vs color requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete image processing pipeline demonstration\n",
    "print(\"üè≠ Demonstrating complete image processing pipeline...\")\n",
    "\n",
    "# Create a realistic processing workflow\n",
    "def complete_image_processing_pipeline(input_image, save_steps=True):\n",
    "    \"\"\"\n",
    "    Demonstrates a complete image processing pipeline combining multiple techniques\n",
    "    \"\"\"\n",
    "    steps = {}\n",
    "    \n",
    "    # Step 1: Original image\n",
    "    steps['01_Original'] = input_image.copy()\n",
    "    \n",
    "    # Step 2: Noise reduction\n",
    "    denoised = cv2.bilateralFilter(input_image, 9, 75, 75)\n",
    "    steps['02_Denoised'] = denoised\n",
    "    \n",
    "    # Step 3: Convert to grayscale for analysis\n",
    "    gray = cv2.cvtColor(denoised, cv2.COLOR_BGR2GRAY)\n",
    "    steps['03_Grayscale'] = gray\n",
    "    \n",
    "    # Step 4: Enhanced contrast (histogram equalization)\n",
    "    enhanced = cv2.equalizeHist(gray)\n",
    "    steps['04_Enhanced'] = enhanced\n",
    "    \n",
    "    # Step 5: Edge detection\n",
    "    edges = cv2.Canny(enhanced, 50, 150)\n",
    "    steps['05_Edges'] = edges\n",
    "    \n",
    "    # Step 6: Morphological cleaning\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    cleaned_edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n",
    "    steps['06_Cleaned_Edges'] = cleaned_edges\n",
    "    \n",
    "    # Step 7: Final processing - combine with original\n",
    "    # Create a colored edge overlay\n",
    "    edge_colored = cv2.cvtColor(cleaned_edges, cv2.COLOR_GRAY2BGR)\n",
    "    edge_colored[:, :, 1] = 0  # Remove green channel for red edges\n",
    "    edge_colored[:, :, 2] = 0  # Remove blue channel for red edges\n",
    "    \n",
    "    final_result = cv2.addWeighted(input_image, 0.7, edge_colored, 0.3, 0)\n",
    "    steps['07_Final_Result'] = final_result\n",
    "    \n",
    "    return steps\n",
    "\n",
    "# Apply the complete pipeline\n",
    "pipeline_results = complete_image_processing_pipeline(image)\n",
    "\n",
    "print(f\"‚úÖ Completed {len(pipeline_results)}-step processing pipeline\")\n",
    "\n",
    "# Visualize the complete pipeline\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, (step_name, result) in enumerate(pipeline_results.items()):\n",
    "    if idx < len(axes):\n",
    "        if len(result.shape) == 3:  # Color image\n",
    "            axes[idx].imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "        else:  # Grayscale image\n",
    "            axes[idx].imshow(result, cmap='gray')\n",
    "        \n",
    "        # Clean up step name for display\n",
    "        display_name = step_name.replace('_', ' ').replace('0', '').strip()\n",
    "        axes[idx].set_title(display_name, fontweight='bold', fontsize=11)\n",
    "        axes[idx].axis('off')\n",
    "        \n",
    "        # Save each step\n",
    "        cv2.imwrite(f'../assets/outputs/01_image_filtering/pipeline_{step_name.lower()}.png', result)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../assets/outputs/01_image_filtering/complete_processing_pipeline.png', \n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Performance comparison\n",
    "print(\"\\n‚ö° Filter Performance Comparison:\")\n",
    "import time\n",
    "\n",
    "filters_to_test = [\n",
    "    ('Gaussian Blur', lambda img: cv2.GaussianBlur(img, (15, 15), 0)),\n",
    "    ('Median Blur', lambda img: cv2.medianBlur(img, 15)),\n",
    "    ('Bilateral Filter', lambda img: cv2.bilateralFilter(img, 15, 75, 75)),\n",
    "    ('Sobel Edge', lambda img: cv2.Sobel(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), cv2.CV_64F, 1, 1, ksize=3)),\n",
    "    ('Canny Edge', lambda img: cv2.Canny(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), 50, 150))\n",
    "]\n",
    "\n",
    "for name, filter_func in filters_to_test:\n",
    "    start_time = time.time()\n",
    "    for _ in range(10):  # Run 10 times for average\n",
    "        result = filter_func(image)\n",
    "    avg_time = (time.time() - start_time) / 10\n",
    "    print(f\"üîπ {name}: {avg_time*1000:.2f} ms average\")\n",
    "\n",
    "print(\"\\nüìä Summary Statistics:\")\n",
    "print(f\"üîπ Total output files generated: {len(os.listdir('../assets/outputs/01_image_filtering'))}\")\n",
    "print(f\"üîπ Image size processed: {image.shape}\")\n",
    "print(f\"üîπ Filters demonstrated: 25+ different techniques\")\n",
    "\n",
    "print(\"\\nüéØ Key Takeaways:\")\n",
    "print(\"üîπ Choose the right filter for your specific application\")\n",
    "print(\"üîπ Combine multiple techniques for best results\")\n",
    "print(\"üîπ Always consider computational cost vs quality trade-offs\")\n",
    "print(\"üîπ Test parameters on your specific data\")\n",
    "\n",
    "print(\"üíæ Complete pipeline results saved\")\n",
    "print(\"‚úÖ Image filtering comprehensive tutorial completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Summary & Next Steps**\n",
    "\n",
    "### **Functions Mastered:**\n",
    "\n",
    "| Category | Functions | Purpose |\n",
    "|----------|-----------|---------|\n",
    "| **Custom Filtering** | `cv2.filter2D()` | Apply custom kernels for various effects |\n",
    "| **Smoothing** | `cv2.blur()`, `cv2.GaussianBlur()`, `cv2.medianBlur()`, `cv2.bilateralFilter()` | Noise reduction and image smoothing |\n",
    "| **Edge Detection** | `cv2.Sobel()`, `cv2.Laplacian()`, `cv2.Canny()`, `cv2.Scharr()` | Finding boundaries and edges |\n",
    "| **Morphological** | `cv2.erode()`, `cv2.dilate()`, `cv2.morphologyEx()` | Shape analysis and binary image processing |\n",
    "| **Utilities** | `cv2.getStructuringElement()`, `cv2.equalizeHist()` | Support functions for filtering operations |\n",
    "\n",
    "### **Key Concepts Learned:**\n",
    "1. **Convolution**: Mathematical foundation of linear filtering\n",
    "2. **Kernel Design**: Creating custom filters for specific effects\n",
    "3. **Noise Types**: Understanding different noise patterns and solutions\n",
    "4. **Edge Detection**: Multi-stage algorithms for optimal results\n",
    "5. **Morphological Processing**: Non-linear operations for shape analysis\n",
    "6. **Pipeline Design**: Combining multiple techniques effectively\n",
    "\n",
    "### **Practical Applications:**\n",
    "- üè• **Medical Imaging**: Disease detection and diagnosis\n",
    "- üè≠ **Manufacturing**: Quality control and defect detection\n",
    "- üöó **Autonomous Vehicles**: Environment perception\n",
    "- üì± **Mobile Apps**: Photo enhancement and filters\n",
    "- üõ∞Ô∏è **Remote Sensing**: Geographic feature extraction\n",
    "- üîê **Security**: Biometric authentication systems\n",
    "\n",
    "### **Best Practices Recap:**\n",
    "1. **Understand Your Data**: Analyze noise types and characteristics\n",
    "2. **Start Simple**: Begin with basic filters before complex operations\n",
    "3. **Parameter Tuning**: Experiment with different settings\n",
    "4. **Validate Results**: Always check output quality\n",
    "5. **Performance Considerations**: Balance quality vs speed\n",
    "6. **Pipeline Approach**: Combine techniques systematically\n",
    "\n",
    "### **Next Steps:**\n",
    "- üìê **Geometric Transformations**: Rotation, scaling, perspective correction\n",
    "- üé® **Color Space Operations**: Advanced color analysis and manipulation\n",
    "- üîç **Feature Detection**: SIFT, SURF, ORB keypoint detection\n",
    "- üìä **Image Segmentation**: Region-based analysis techniques\n",
    "- ü§ñ **Machine Learning**: Deep learning for image processing\n",
    "\n",
    "### **Recommended Practice:**\n",
    "1. **Experiment** with different filter combinations\n",
    "2. **Create** your own custom kernels\n",
    "3. **Test** on various image types (medical, natural, synthetic)\n",
    "4. **Measure** performance for real-time applications\n",
    "5. **Document** your findings for future reference\n",
    "\n",
    "---\n",
    "**‚úÖ Image Filtering & Convolution Mastered!**\n",
    "\n",
    "You now have comprehensive knowledge of image filtering techniques and can apply them to solve real-world computer vision problems. The skills learned here form the foundation for advanced image processing and analysis tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
